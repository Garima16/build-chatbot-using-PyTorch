{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHzRzqYNlmGL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Xt5IarmDl_LE",
    "outputId": "0c972d35-d3bb-46db-ade0-4099304d25b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# to provide easy switching between cpu and gpu\n",
    "CUDA = print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxExTYw-3mWY"
   },
   "source": [
    "# Part 1 :  **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "vh_ALj0QkiTM",
    "outputId": "b6fc8a04-d4ea-445c-cde0-655fc5a9bfe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n"
     ]
    }
   ],
   "source": [
    "with open('movie_conversations.txt','r') as conv_file:\n",
    "  convs = conv_file.readlines()\n",
    "for conv in convs[:10]:\n",
    "  print(conv.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "7dNqOrE3nXNS",
    "outputId": "c8833928-4e40-4f5c-8d60-9c05dbe807a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?'\n"
     ]
    }
   ],
   "source": [
    "with open('movie_lines.txt', 'r', errors='replace') as lines_file:\n",
    "  lines = lines_file.readlines()\n",
    "for line in lines[:10]:\n",
    "  print(line.encode('utf-8').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZEl5-KmmC3D"
   },
   "outputs": [],
   "source": [
    "line_fields = ['lineID', 'charID', 'movieID', 'char_name', 'text']\n",
    "lines = {}\n",
    "with open('movie_lines.txt','r',encoding='iso-8859-1') as file: #encodes ASCII chars, single Byte encoding method\n",
    "#   head = [next(file) for x in range(10)]\n",
    "  for line in file:\n",
    "    vals = line.strip().split('+++$+++')\n",
    "    lineID = vals[0].strip(' ')\n",
    "    line_obj = {}\n",
    "    line_obj['lineID'] = lineID\n",
    "    for i in range(1,len(vals)):\n",
    "      line_obj[line_fields[i]] = vals[i]\n",
    "    lines[line_obj['lineID']] = line_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVLXHXmhGWPh"
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DEOdehHqvZic",
    "outputId": "511298e6-753c-4530-f477-e5ad5a83a39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L194', 'L195', 'L196', 'L197']\",\n",
      "  'lines': [{'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L194',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Can we make this quick?  Roxanne Korrine and Andrew '\n",
      "                     'Barrett are having an incredibly horrendous public '\n",
      "                     'break- up on the quad.  Again.'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L195',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" Well, I thought we'd start with pronunciation, if \"\n",
      "                     \"that's okay with you.\"},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L196',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Not the hacking and gagging and spitting part.  '\n",
      "                     'Please.'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L197',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" Okay... then how 'bout we try out some French cuisine.  \"\n",
      "                     'Saturday?  Night?'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L198', 'L199']\",\n",
      "  'lines': [{'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L198',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" You're asking me out.  That's so cute. What's your name \"\n",
      "                     'again?'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L199',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Forget it.'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L200', 'L201', 'L202', 'L203']\",\n",
      "  'lines': [{'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L200',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" No, no, it's my fault -- we didn't have a proper \"\n",
      "                     'introduction ---'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L201',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Cameron.'},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L202',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" The thing is, Cameron -- I'm at the mercy of a \"\n",
      "                     'particularly hideous breed of loser.  My sister.  I '\n",
      "                     \"can't date until she does.\"},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L203',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Seems like she could get a date easy enough...'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L204', 'L205', 'L206']\",\n",
      "  'lines': [{'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L204',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Why?'},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L205',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Unsolved mystery.  She used to be really popular when '\n",
      "                     'she started high school, then it was just like she got '\n",
      "                     'sick of it or something.'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L206',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" That's a shame.\"}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L207', 'L208']\",\n",
      "  'lines': [{'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L207',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Gosh, if only we could find Kat a boyfriend...'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L208',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Let me see what I can do.'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L271', 'L272', 'L273', 'L274', 'L275']\",\n",
      "  'lines': [{'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L271',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" C'esc ma tete. This is my head\"},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L272',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" Right.  See?  You're ready for the quiz.\"},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L273',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" I don't want to know how to say that though.  I want to \"\n",
      "                     'know useful things. Like where the good stores are.  How '\n",
      "                     'much does champagne cost?  Stuff like Chat.  I have '\n",
      "                     'never in my life had to point out my head to someone.'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L274',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" That's because it's such a nice one.\"},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L275',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Forget French.'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L276', 'L277']\",\n",
      "  'lines': [{'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L276',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' How is our little Find the Wench A Date plan '\n",
      "                     'progressing?'},\n",
      "            {'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L277',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" Well, there's someone I think might be --\"}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L280', 'L281']\",\n",
      "  'lines': [{'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L280',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' There.'},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L281',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' Where?'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L363', 'L364']\",\n",
      "  'lines': [{'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L363',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' You got something on your mind?'},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L364',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' I counted on you to help my cause. You and that thug '\n",
      "                     \"are obviously failing. Aren't we ever going on our \"\n",
      "                     'date?'}],\n",
      "  'movieID': ' m0 '},\n",
      " {'char1ID': 'u0 ',\n",
      "  'char2ID': ' u2 ',\n",
      "  'dialoguesIDs': \" ['L365', 'L366']\",\n",
      "  'lines': [{'charID': ' u2 ',\n",
      "             'char_name': ' CAMERON ',\n",
      "             'lineID': 'L365',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': ' You have my word.  As a gentleman'},\n",
      "            {'charID': ' u0 ',\n",
      "             'char_name': ' BIANCA ',\n",
      "             'lineID': 'L366',\n",
      "             'movieID': ' m0 ',\n",
      "             'text': \" You're sweet.\"}],\n",
      "  'movieID': ' m0 '}]\n"
     ]
    }
   ],
   "source": [
    "conv_fields = ['char1ID', 'char2ID', 'movieID', 'dialoguesIDs']\n",
    "convs = []\n",
    "with open('movie_conversations.txt', 'r', encoding='iso-8859-1') as file:\n",
    "  for line in file:\n",
    "    vals = line.strip().split('+++$+++')\n",
    "    conv_obj = {}\n",
    "    for i in range(len(vals)):\n",
    "      conv_obj[conv_fields[i]] = vals[i]\n",
    "    lineIDs = conv_obj['dialoguesIDs'] # get line IDs from dialoguesIDs string, string type\n",
    "    lineIDs = lineIDs[2:-1] # remove braces from string \n",
    "    conv_obj[\"lines\"] = []\n",
    "    \n",
    "    for lineID in lineIDs.split(','): # split line IDs separated by ','\n",
    "      lineID = lineID.strip('\\' ')\n",
    "      try:\n",
    "        conv_obj[\"lines\"].append(lines[lineID]) #search for that line in lines dict with this linsID\n",
    "      except KeyError:\n",
    "        not_found += 1\n",
    "#         print(\"here\")\n",
    "        not_found.append(lineID)\n",
    "    convs.append(conv_obj)\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(convs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83097\n"
     ]
    }
   ],
   "source": [
    "print(len(convs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221282\n"
     ]
    }
   ],
   "source": [
    "#extract pairs of conversations\n",
    "conv_pairs = []\n",
    "for conv in convs :\n",
    "    for i in range(len(conv['lines'])-1):\n",
    "        conv1 = conv['lines'][i]['text']\n",
    "        conv2 = conv['lines'][i+1]['text']\n",
    "        if conv1 and conv2:\n",
    "            conv_pairs.append([conv1, conv2])\n",
    "print(len(conv_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new file containing conversation pairs\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "with open(\"conv_pairs.txt\", \"w\", encoding='utf-8') as out_file:\n",
    "    writer = csv.writer(out_file, delimiter=delimiter)\n",
    "    for pair in conv_pairs:\n",
    "        writer.writerow(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221282\n",
      "b\" Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\t Well, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
      "b\" Well, I thought we'd start with pronunciation, if that's okay with you.\\t Not the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
      "b\" Not the hacking and gagging and spitting part.  Please.\\t Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n",
      "b\" You're asking me out.  That's so cute. What's your name again?\\t Forget it.\\r\\n\"\n",
      "b\" No, no, it's my fault -- we didn't have a proper introduction ---\\t Cameron.\\r\\n\"\n",
      "b\" Cameron.\\t The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\n\"\n",
      "b\" The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\t Seems like she could get a date easy enough...\\r\\n\"\n",
      "b' Why?\\t Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\n'\n",
      "b\" Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\t That's a shame.\\r\\n\"\n",
      "b' Gosh, if only we could find Kat a boyfriend...\\t Let me see what I can do.\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "with open('conv_pairs.txt','rb') as file:\n",
    "    lines = file.readlines()\n",
    "    print(len(lines))\n",
    "    for line in lines[:10]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 : **Processing the words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn unicode string to plain ascii\n",
    "\n",
    "# NFD : Normal Form Decomposed - decomposes the chars and combines it together\n",
    "# Mn : none marking space\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    \n",
    "    # replace any char(?!.) by whitespace + char\n",
    "    # \\1 means first bracketed group --> [?!.]\n",
    "    # r is not to consider \\1 as a character\n",
    "    # r to escape backslash\n",
    "    s = re.sub(r\"([?!.])\", r\" \\1\",s)\n",
    "    \n",
    "    # remove any char that's not a sequence of  [a-zA-z?!.] \n",
    "    s = re.sub(r\"[^a-zA-z?!.]+\", r\" \", s)\n",
    "    \n",
    "    # remove sequence of whitespace chars\n",
    "    s = re.sub(r\"\\s+\", r\" \", s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frjf ? ! .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalise_string(\"frjf45  ? !.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing file\n",
      "done processing\n"
     ]
    }
   ],
   "source": [
    "datafile = 'conv_pairs.txt'\n",
    "\n",
    "# list 'lines' elements are conversation pairs\n",
    "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
    "print(\"reading and processing file\")\n",
    "\n",
    "# for each dialogue in the pair, normalise the dialogue string\n",
    "# pairs of normalised strings are obtained\n",
    "pairs = [[normalise_string(s) for s in pairs.split('\\t')] for pairs in lines]\n",
    "\n",
    "print(\"done processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n",
       "  'well i thought we d start with pronunciation if that s okay with you .'],\n",
       " ['well i thought we d start with pronunciation if that s okay with you .',\n",
       "  'not the hacking and gagging and spitting part . please .'],\n",
       " ['not the hacking and gagging and spitting part . please .',\n",
       "  'okay . . . then how bout we try out some french cuisine . saturday ? night ?'],\n",
       " ['you re asking me out . that s so cute . what s your name again ?',\n",
       "  'forget it .'],\n",
       " ['no no it s my fault we didn t have a proper introduction ', 'cameron .'],\n",
       " ['cameron .',\n",
       "  'the thing is cameron i m at the mercy of a particularly hideous breed of loser . my sister . i can t date until she does .'],\n",
       " ['the thing is cameron i m at the mercy of a particularly hideous breed of loser . my sister . i can t date until she does .',\n",
       "  'seems like she could get a date easy enough . . .'],\n",
       " ['why ?',\n",
       "  'unsolved mystery . she used to be really popular when she started high school then it was just like she got sick of it or something .'],\n",
       " ['unsolved mystery . she used to be really popular when she started high school then it was just like she got sick of it or something .',\n",
       "  'that s a shame .'],\n",
       " ['gosh if only we could find kat a boyfriend . . .',\n",
       "  'let me see what i can do .']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221282"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep conversation pairs where dialogue length <= 10 words, check both dialogues\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "def filter_pairs(s):\n",
    "    # check that both dialogues' length < 2= 10\n",
    "    return len(s[0].split()) <= MAX_LENGTH and len(s[1].split()) <= MAX_LENGTH\n",
    "\n",
    "# keep only those pairs that return true for above function\n",
    "pairs = [pair for pair in pairs if filter_pairs(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75024"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 'pairs' - list of pair of dialogues,return max length of any dialogue in pairs\n",
    "def max_len_of_dialogue(pairs):\n",
    "    max_len = 0\n",
    "    for pair in pairs[:10]:\n",
    "        p1 = pair[0].split()\n",
    "        p2 = pair[1].split()\n",
    "        l1 = len(p1)\n",
    "        l2 = len(p2)\n",
    "        max_len = l1 if l1 > max_len else l2 if l2 > max_len else max_len\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [pair for pair in pairs if len(pair)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75024"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Vocabulary():\n",
    "    def __init__(self, name):\n",
    "        self.name = name # assign name to different vocabularies, if there are > 1\n",
    "        self.word2ind = {} # dictionary to store unique index for each word in dictionary{word:id}\n",
    "        self.word2count = {} # store frequency of each word\n",
    "        self.ind2word = {PAD_token:\"PAD\", SOS_token:\"SOS\", EOS_token:\"EOS\"}  #id:word\n",
    "        self.num_words = 3 #PAD, SOS, EOS\n",
    "    \n",
    "    def word_count(self, sentence): # function to count word frequency and add word in vocabulary\n",
    "        for word in sentence.split(' '):\n",
    "            try: # if the word exists, increment its count\n",
    "                self.word2count[word] += 1 \n",
    "            except KeyError: # if the word doesnot already exist in vocabulary\n",
    "                self.word2count[word] = 1\n",
    "                #self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        self.word2ind[word] = self.num_words \n",
    "        self.ind2word[self.num_words] = word\n",
    "        self.num_words += 1\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"Vocabulary size: {}\".format(str(self.num_words))\n",
    "    \n",
    "    # remove ethose words from vocabulary whose frequency is below certain threshold\n",
    "    def trim(self, threshold):\n",
    "        deleted_words = 0\n",
    "        for k,v in self.word2count.items():\n",
    "            if v < threshold:\n",
    "                deleted_words += 1\n",
    "                self.word2count[k]= 0 # set frequency of word in word2count dict = 0\n",
    "            else:\n",
    "                self.add_word(k)\n",
    "        #for word in self.word2count.keys():\n",
    "         #   if self.word2count[word] > 0:\n",
    "          #      self.add_word(word)\n",
    "        \n",
    "        words_in_vocab = len(self.word2ind)\n",
    "        words_in_corpus = words_in_vocab + deleted_words\n",
    "    \n",
    "        print(\"keep words {}/{} = {:.4f}\".format(words_in_vocab, words_in_corpus, words_in_vocab/words_in_corpus ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(\"cornell-movie-dialogues-corpus\")\n",
    "MIN_FREQ = 3 # only keep words with frequqncy >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep words 9045/20173 = 0.4484\n"
     ]
    }
   ],
   "source": [
    "# add words to vocab whose frequency >= 3\n",
    "for pair in pairs:\n",
    "    vocab.word_count(pair[0])\n",
    "    vocab.word_count(pair[1])\n",
    "    \n",
    "vocab.trim(MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75024"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pairs(): # remove those pairs whose any of the 2 dialogues contains infrequent words\n",
    "    keep_pairs = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        keep_first = True # flag to keep or remove 1st dialogue\n",
    "        keep_sec = True# flag to keep or remove 2nd dialogue\n",
    "        for word in pair[0].split(): # 1st dialogue\n",
    "            if word not in vocab.word2ind:\n",
    "                keep_first = False\n",
    "                break\n",
    "        for word in pair[1].split(): # 2nd dialogue\n",
    "            if word not in vocab.word2ind:\n",
    "                keep_sec = False\n",
    "                break\n",
    "        if keep_first and keep_sec :\n",
    "             keep_pairs.append(pair)\n",
    "    return keep_pairs\n",
    "    #print(\"pairs earlier : {}, pairs now: {}\".format(len(pairs),len(keep_pairs)))\n",
    "\n",
    "pairs = remove_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62751\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentences(voc_obj, sentence):\n",
    "    return [voc_obj.word2ind[word] for word in sentence.split()]+[EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burt reynolds .\n",
      "[7045, 3376, 11, 2]\n"
     ]
    }
   ],
   "source": [
    "print(pairs[60000][0])\n",
    "print(indexes_from_sentences(vocab, pairs[60000][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1277"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2ind['interested']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9048\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that s because it s such a nice one .', 'there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?']\n",
      "[[3, 4, 5, 6, 4, 7, 8, 9, 10, 11, 2], [14, 11, 2], [17, 18, 19, 20, 11, 21, 8, 22, 2], [25, 11, 2], [18, 40, 31, 16, 2], [42, 43, 11, 11, 11, 2], [44, 3, 4, 45, 17, 46, 47, 48, 11, 2], [49, 2], [54, 17, 55, 47, 52, 56, 16, 2], [57, 58, 59, 16, 2]]\n"
     ]
    }
   ],
   "source": [
    "inp = []\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "print(inp)\n",
    "ind = [indexes_from_sentences(vocab, sentence) for sentence in inp]\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EOS'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.ind2word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.zip_longest at 0x7efdd7bafa98>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['a', 'b', 'c', 'd', 'e']\n",
    "b = [1,2,3]\n",
    "c = itertools.zip_longest(a,b)\n",
    "c\n",
    "#list(c) # an iterator is returned which is then converted to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(c) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 2), ('c', 3), ('d', None), ('e', None)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 14, 17, 25, 18, 42, 44, 49, 54, 57),\n",
       " (4, 11, 18, 11, 40, 43, 3, 2, 17, 58),\n",
       " (5, 2, 19, 2, 31, 11, 4, 0, 55, 59),\n",
       " (6, 0, 20, 0, 16, 11, 45, 0, 47, 16),\n",
       " (4, 0, 11, 0, 2, 11, 17, 0, 52, 2),\n",
       " (7, 0, 21, 0, 0, 2, 46, 0, 56, 0),\n",
       " (8, 0, 8, 0, 0, 0, 47, 0, 16, 0),\n",
       " (9, 0, 22, 0, 0, 0, 48, 0, 2, 0),\n",
       " (10, 0, 2, 0, 0, 0, 11, 0, 0, 0),\n",
       " (11, 0, 0, 0, 0, 0, 2, 0, 0, 0),\n",
       " (2, 0, 0, 0, 0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.zip_longest(*ind, fillvalue=0)) # zip values colummn-wise, fill 0 at places where None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(l, fillvalue=0): # default padding is with 0s\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 5, 6, 4, 7, 8, 9, 10, 11, 2], [14, 11, 2], [17, 18, 19, 20, 11, 21, 8, 22, 2], [25, 11, 2], [18, 40, 31, 16, 2], [42, 43, 11, 11, 11, 2], [44, 3, 4, 45, 17, 46, 47, 48, 11, 2], [49, 2], [54, 17, 55, 47, 52, 56, 16, 2], [57, 58, 59, 16, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length will be 11 as EOS token is also appended at the end of each sentence\n",
    "leng = [len(index) for index in ind]\n",
    "max(leng) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 14, 17, 25, 18, 42, 44, 49, 54, 57),\n",
       " (4, 11, 18, 11, 40, 43, 3, 2, 17, 58),\n",
       " (5, 2, 19, 2, 31, 11, 4, 0, 55, 59),\n",
       " (6, 0, 20, 0, 16, 11, 45, 0, 47, 16),\n",
       " (4, 0, 11, 0, 2, 11, 17, 0, 52, 2),\n",
       " (7, 0, 21, 0, 0, 2, 46, 0, 56, 0),\n",
       " (8, 0, 8, 0, 0, 0, 47, 0, 16, 0),\n",
       " (9, 0, 22, 0, 0, 0, 48, 0, 2, 0),\n",
       " (10, 0, 2, 0, 0, 0, 11, 0, 0, 0),\n",
       " (11, 0, 0, 0, 0, 0, 2, 0, 0, 0),\n",
       " (2, 0, 0, 0, 0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = zero_padding(ind) # in padded, max_len(11) is now the number of rows, #cols = batch size\n",
    "print(len(padded))\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find actual words in list l, if padded_token found(value 0),put 0, else 1\n",
    "def binary_padding(l):\n",
    "    m = []\n",
    "    for i,seq in enumerate(padded):\n",
    "        m.append([])\n",
    "        for ind in seq:\n",
    "            if ind == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_padding(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_var(l, vocab):\n",
    "    indexes_batch = [indexes_from_sentences(vocab, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(ind) for ind in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    return pad_var, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_var(l, vocab):\n",
    "    indexes_batch = [indexes_from_sentences(vocab, sentence) for sentence in l]\n",
    "    max_target_len = max([len(ind) for ind in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    mask = torch.ByteTensor(binary_padding(pad_list))\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    return max_target_len, mask, pad_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch2train_data(batch_pairs, vocab):\n",
    "    \n",
    "    # arrange pairs in decreasing order of length of 1st dialogue(question)\n",
    "    batch_pairs.sort(key = lambda x : len(x[0].split()), reverse=True)\n",
    "    ques_batch,replies_batch = [],[]\n",
    "    for pair in batch_pairs:\n",
    "        ques_batch.append(pair[0])\n",
    "        replies_batch.append(pair[1])\n",
    "    inp, lengths = input_var(ques_batch, vocab)\n",
    "    max_target_len, mask, output = output_var(replies_batch, vocab)\n",
    "    return inp, lengths, max_target_len, mask, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what are you going to do ? hm ?', 'if you hit me . . .'], ['do you still want the operation ?', 'yeah . . . yeah .'], ['good . see ya soon .', 'good luck .'], ['any brothers ? sisters ?', 'dick jane and spot .'], ['what s the matter ?', 'you fixed this suit ? beth ?']]\n",
      "inp tensor([[  57,   54,   58,  236,   57],\n",
      "        [ 112,   17,   11, 3890,    4],\n",
      "        [  17,  362,  394,   16,   61],\n",
      "        [ 149,  144,  239, 3973,  372],\n",
      "        [  47,   61, 1238,   16,   16],\n",
      "        [  54,  760,   11,    2,    2],\n",
      "        [  16,   16,    2,    0,    0],\n",
      "        [2674,    2,    0,    0,    0],\n",
      "        [  16,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths tensor([10,  8,  7,  6,  6])\n",
      "max_target_len 8\n",
      "mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
      "        [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
      "        [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
      "        [1, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8)\n",
      "output tensor([[ 152,  197,   58,  877,   17],\n",
      "        [  17,   11,  623, 3974, 1843],\n",
      "        [ 576,   11,   11,  148,   52],\n",
      "        [  94,   11,    2, 1948, 1684],\n",
      "        [  11,  197,    0,   11,   16],\n",
      "        [  11,   11,    0,    2, 3458],\n",
      "        [  11,    2,    0,    0,   16],\n",
      "        [   2,    0,    0,    0,    2]])\n"
     ]
    }
   ],
   "source": [
    "# test above function with a small batch size\n",
    "bs = 5\n",
    "\n",
    "# randomly select 5 dialogue pairs from 'pairs'\n",
    "pairs = [random.choice(pairs) for _ in range(bs)]\n",
    "print(pairs)\n",
    "inp, lengths, max_target_len, mask, output = batch2train_data(pairs,vocab) \n",
    "print(\"inp\", inp)\n",
    "print(\"lengths\", lengths)\n",
    "print(\"max_target_len\", max_target_len)\n",
    "print(\"mask\", mask)\n",
    "print(\"output\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Defining the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder in GRU only gives one output - the hidden state output. \n",
    "\n",
    "    For encoder:\n",
    "    Steps to be taken are : convert word indexes to embeddings, Pack padded batch of sequences for RNN module, Forward pass through GRU, Unpack padding, Finally return output and final hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #the input is word embedding whose size is that of hidden layer\n",
    "        #arguments - input size, hidden size, n_layers, dropout, bidirectional(default value-False)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers=1 else droput))\n",
    "        \n",
    "    def forward(self, inp_seq, inp_length, hidden=None):\n",
    "        # inp_seq shape(which will be pack padded seq) = (batch_size,max_len)\n",
    "        # inp_lengths : length of all input sentences in batch\n",
    "        # hidden(n_layers * num_directions, batch, hidden_size) : initial hidden state for each element in batch\n",
    "        \n",
    "        #convert word indexes to embeddings\n",
    "        embedded = self.embedding(inp_seq)\n",
    "        \n",
    "        #pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded)\n",
    "        \n",
    "        #forward pass through GRU\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        #unpack padding\n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output)\n",
    "        \n",
    "        #return final output and final hidden state\n",
    "        return output, hidden"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Building chatbot in PyTorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
